# Deep-Q-network
Very basic Deep Q network.

The intention was to  make a DQN to work with several OpenAI gym environments without looking-up any code, I made this completely out of my understanding of DQN, even though I know many other techniques I desided to start slowly and made the agent consisting of Monte-carlo for value function calculation, no full experience replay, actions are given as features rather than as an output. I highlighted the problems more detailed in the notebook. Also the architecture of the class itself can be optimized in many ways.
